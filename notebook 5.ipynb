{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('spanish')\n",
    "from functions import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIMPLE RECOMMENDATION ENGINE WITH COUNT VECTORIZER\n",
    "### 2 NGRAMS FOR DESCRIPTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the original database (we should have saved a copy before all cleaning, sorry about that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../datasets/henry_lab_disk/properties_colombia_train.csv', sep = ',')\n",
    "train.drop('id', axis=1, inplace=True)\n",
    "train.rename(columns={'Unnamed: 0':'id'}, inplace=True)\n",
    "train.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the usual cleaning we do in train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['target'] = np.where(train['price'] > train['price'].mean(), 1, 0)\n",
    "train = train[['title', 'description', 'target']]\n",
    "train['target'].fillna(0, inplace=True)\n",
    "train['description'].fillna(' ', inplace=True)\n",
    "train['title'].fillna(' ', inplace=True)\n",
    "train = trim_all_columns(train)\n",
    "train['title'] = normalize_column(train, 'title')\n",
    "train['description'] = normalize_column(train, 'description')\n",
    "train['title'] = train['title'].str.lower().str.strip()\n",
    "train['description'] = train['description'].str.lower().str.strip()\n",
    "pattern = '|'.join(['\\n','\\r', '\\t' ,'\\xa0','\\u200b',','])\n",
    "train['title'] = clean_values(train['title'], pattern, value=' ')\n",
    "train['description'] = clean_values(train['description'], pattern, value=' ')\n",
    "pattern2 = '|'.join(['_', '[(|)]', '-',':',';'])\n",
    "train['title'] = clean_values(train['title'], pattern2, regex = True, value=' ')\n",
    "train['description'] = clean_values(train['description'], pattern2, regex = True, value=' ')\n",
    "train['title'] = clean_values(train['title'], r\"\\<.*?\\>\", regex = True, value=' ')\n",
    "train['description'] = clean_values(train['description'], pattern2, regex = True, value=' ')\n",
    "train['title'] = clean_values(train['title'], r\"\\{.*?\\}\", regex = True, value=' ')\n",
    "train['description'] = clean_values(train['description'], pattern2, regex = True, value=' ')\n",
    "train['title'] = train['title'].str.replace(' +',' ', regex=True)\n",
    "train['description'] = train['description'].str.replace(' +',' ', regex = True)\n",
    "train['description'] = train['description'].str.replace('br / ','',regex = False)\n",
    "train['description'] = train['description'].str.replace('/b','',regex = False)\n",
    "train['description'] = train['description'].str.replace(' br ','',regex = False)\n",
    "train['description'] = train['description'].str.replace(' b ','',regex = False)\n",
    "train['description'] = train['description'].str.replace('&aacute ','a',regex = False)\n",
    "train['description'] = train['description'].str.replace('&eacute ','e',regex = False)\n",
    "train['description'] = train['description'].str.replace('&iacute ','i',regex = False)\n",
    "train['description'] = train['description'].str.replace('&oacute ','o',regex = False)\n",
    "train['description'] = train['description'].str.replace('&uacute ','u',regex = False)\n",
    "train['description'] = train['description'].str.replace('&ntilde ','ñ',regex = False)\n",
    "train['description'] = train['description'].str.replace('ref#\\d+','',regex = True)\n",
    "train['description'] = train['description'].str.replace('!!!','',regex = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get hands on, and CountVectorize everything\n",
    "\n",
    "https://towardsdatascience.com/basics-of-countvectorizer-e26677900f9c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the classifier on the test set is 0.894\n"
     ]
    }
   ],
   "source": [
    "# Create CountVectorizer object\n",
    "vectorizer = CountVectorizer(strip_accents='ascii', stop_words=stopwords, lowercase=False, ngram_range=(1,2))\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train['description'], \n",
    "train['target'], test_size=0.2,stratify=train['target'], random_state = 1234)\n",
    "\n",
    "# Generate training Bow vectors\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "# Generate test BoW vectors\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "\n",
    "# Create MultinomialNB object\n",
    "clf = MultinomialNB()\n",
    "# Train clf\n",
    "clf.fit(X_train_bow, y_train)\n",
    "# Compute accuracy on test set\n",
    "accuracy = clf.score(X_test_bow, y_test)\n",
    "\n",
    "print(\"The accuracy of the classifier on the test set is %.3f\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../datasets/henry_lab_disk/properties_colombia_test.csv', sep = ',')\n",
    "test.drop('id', axis=1, inplace=True)\n",
    "test.rename(columns={'Unnamed: 0':'id'}, inplace=True)\n",
    "test.set_index('id', inplace=True)\n",
    "test = test[['title', 'description']]\n",
    "test['description'].fillna(' ', inplace=True)\n",
    "test['title'].fillna(' ', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test['target'] = np.where(test['price'] > test['price'].mean(), 1, 0)\n",
    "test = test[['title', 'description']]#, 'target']]\n",
    "#test['target'].fillna(0, inplace=True)\n",
    "test['description'].fillna(' ', inplace=True)\n",
    "test['title'].fillna(' ', inplace=True)\n",
    "test = trim_all_columns(test)\n",
    "test['title'] = normalize_column(test, 'title')\n",
    "test['description'] = normalize_column(test, 'description')\n",
    "test['title'] = test['title'].str.lower().str.strip()\n",
    "test['description'] = test['description'].str.lower().str.strip()\n",
    "pattern = '|'.join(['\\n','\\r', '\\t' ,'\\xa0','\\u200b',','])\n",
    "test['title'] = clean_values(test['title'], pattern, value=' ')\n",
    "test['description'] = clean_values(test['description'], pattern, value=' ')\n",
    "pattern2 = '|'.join(['_', '[(|)]', '-',':',';'])\n",
    "test['title'] = clean_values(test['title'], pattern2, regex = True, value=' ')\n",
    "test['description'] = clean_values(test['description'], pattern2, regex = True, value=' ')\n",
    "test['title'] = clean_values(test['title'], r\"\\<.*?\\>\", regex = True, value=' ')\n",
    "test['description'] = clean_values(test['description'], pattern2, regex = True, value=' ')\n",
    "test['title'] = clean_values(test['title'], r\"\\{.*?\\}\", regex = True, value=' ')\n",
    "test['description'] = clean_values(test['description'], pattern2, regex = True, value=' ')\n",
    "test['title'] = test['title'].str.replace(' +',' ', regex=True)\n",
    "test['description'] = test['description'].str.replace(' +',' ', regex = True)\n",
    "test['description'] = test['description'].str.replace('br / ','',regex = False)\n",
    "test['description'] = test['description'].str.replace('/b','',regex = False)\n",
    "test['description'] = test['description'].str.replace(' br ','',regex = False)\n",
    "test['description'] = test['description'].str.replace(' b ','',regex = False)\n",
    "test['description'] = test['description'].str.replace('&aacute ','a',regex = False)\n",
    "test['description'] = test['description'].str.replace('&eacute ','e',regex = False)\n",
    "test['description'] = test['description'].str.replace('&iacute ','i',regex = False)\n",
    "test['description'] = test['description'].str.replace('&oacute ','o',regex = False)\n",
    "test['description'] = test['description'].str.replace('&uacute ','u',regex = False)\n",
    "test['description'] = test['description'].str.replace('&ntilde ','ñ',regex = False)\n",
    "test['description'] = test['description'].str.replace('ref#\\d+','',regex = True)\n",
    "test['description'] = test['description'].str.replace('!!!','',regex = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment predicted by the classifier is 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['espectacular casa campestre para la venta en condominio miralia en dapa cuenta con mas de 454 mts construidos divididos en la casa principal de dos niveles que tiene sala comedor cocina rustica colonial zona de estudio cuarto de servicio tres cuartos con bano y posibilidad de cuarta habitacion chimenea habitacion principal con bano completo con jacuzzi escaleras descansadas casa con excelente altura balcon con hermosa vista panoramica mas de 50 arboles frutales la casa tiene am'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the sentiment of a expensive sale\n",
    "review1 = test['description'].sample().values\n",
    "prediction = clf.predict(vectorizer.transform([str(review1)]))[0]\n",
    "print(\"The sentiment predicted by the classifier is %i\" % (prediction))\n",
    "review1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment predicted by the classifier is 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['codigo inmueble 6262 codigo interno 6262 no pierdas esta oportunidad!! comodo apartamento con 2 habitaciones 2 closets sala comedor cocina integral 2 bano. su ambiente calido con comodos espacios comunes lo convierten en una excelente alternativa para vivir. porque los asuntos importantes deben quedar en manos de expertos llamanos para ampliarte la informacion.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the sentiment of a expensive sale\n",
    "review2 = test['description'].sample().values\n",
    "prediction = clf.predict(vectorizer.transform([str(review2)]))[0]\n",
    "print(\"The sentiment predicted by the classifier is %i\" % (prediction))\n",
    "review2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65850"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65850"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "for i in range(test.shape[0]):\n",
    "    prediction = clf.predict(vectorizer.transform([str(test.iloc[i,1])]))[0]\n",
    "    predictions.append(prediction)\n",
    "\n",
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predictions, columns=['target'])\n",
    "df.to_csv('./data/predictions/predictions_nlp_recommendation_v2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11f276e131df8708bc2fc0bb3682099dca2cbd19e2af230e0a94f818ba1c6df6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
